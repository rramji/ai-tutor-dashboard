{
  "student_id": "7ce8ef380fe542d20e89b17746bd92738a6e3c4c850cb7e9b22e579ae728df84",
  "interactions": [
    {
      "content": "#### Section 1: Invisible worlds\nMaterials and phenomena that occur on the nanoscale are, almost by\ndefinition, too small for the human visual sense. Nevertheless, we\nreally do know their shapes, sizes, and compositions. To obtain this\ninformation, we rely on techniques of **characterization**. Namely, on\nthe two closely related areas of **spectroscopy** and *imaging*.\nSpectroscopy is the processes by which matter is bombarded with some\ntype of particle or radiation, and the particles that are scattered,\ntransmitted, or re-emitted are analyzed for clues about the structure.\nImaging techniques use a similar paradigm, but the end goal is not to\nproduce a quantitative spectrum but a visual image for processing (often\nby the human brain). There are many modalities which combine\nspectroscopy and imaging in a single instrument. For a video primer to\nthis chapter, visit \n>>>video(https://youtu.be/N18UhNQmI8o)\n\nOne of the things that differentiates science from everyday rational\nbehavior is that science needs special tools to overcome the limits of\nhuman senses. We can only learn so much about the world from our senses\nof sight, smell, hearing, touch, and taste. While we can determine some\nthings about the structure and properties of matter from our five basic\nsenses, we need to correlate these observations to information gleaned\nfrom other tools. Nowhere is the augmentation of human senses more\nnecessary than in nanoengineering, where everything is way too small to\nsee with even the most powerful optical microscopes. For example, a\nnanoparticle or quantum dot might have a diameter of 5 nm, but the\nsmallest wavelength of light that can be detected by the human eye is\nabout 400 nm, which corresponds to violet light. So, we are blind to\nnanomaterials. That's why we can't see viruses billowing out of people's\nmouths and noses, and it's also why we can't see the intricate details\nof a computer microprocessor at the level of the transistor, even under\nthe highest possible magnification with a conventional microscope.\n\nThus, there is a conundrum posed by the diffraction limit of light. The\nway to circumvent this problem is to use particles other than visible\nphotons, such as electrons, ultraviolet rays, X-rays, or even helium\nnuclei. These approaches are analogous to optical microscopy in that\nthey use wavelike particles to interact with matter, and the image is\ncreated from the ways in which light is absorbed or scattered from the\nsurface.\n\nSuch methods of obtaining images of nanoscale objects are not limited\nonly to modalities which shine---or blast---light or particles upon the\nsample. The other major way in which information is collected about the\ncomposition and structure of nanoscale materials is not by shining a\nbeam from a distance, but rather by physical contact or near-physical\ncontact, in methods that are akin not to the sense of vision but to the\nsense of touch. Such approaches are referred to collectively as\n\"scanning probe\" techniques. The feature that all scanning probe\ninstruments have in common is the use of a sharp object which scans\nalong a surface (like a vinyl or LP player). The tip can be used to plot\nthe topography, mechanical properties, conductivity, chemical\ncomposition, or other properties of the surface. Finally, there are\ntechniques which use radiation not to generate images, but to probe the\nstructure of atoms, molecules, particles, and surfaces. These\nspectroscopic modalities rely on the basic physics we have covered in\ndetail in Chapter 8, so we will begin here.\n",
      "role": "assistant",
      "timestamp": "2025-03-14T07:17:36.472950"
    },
    {
      "content": "Do you have any questions?",
      "role": "assistant",
      "timestamp": "2025-03-14T07:17:36.621671"
    },
    {
      "content": "What is spectroscopy?",
      "role": "user",
      "timestamp": "2025-03-14T07:17:50.879679"
    },
    {
      "content": "Spectroscopy is a process where matter is bombarded with particles or radiation, and the scattered, transmitted, or re-emitted particles are analyzed to learn about the structure of the matter. The textbook explains this concept in the first paragraph.",
      "role": "assistant",
      "timestamp": "2025-03-14T07:17:53.048545"
    },
    {
      "content": "What matter?",
      "role": "user",
      "timestamp": "2025-03-14T07:19:17.976680"
    },
    {
      "content": "The term \"matter\" in this context refers to any material being studied or analyzed. This could include atoms, molecules, nanoparticles, or larger structures. Is there a specific type of matter you're curious about?",
      "role": "assistant",
      "timestamp": "2025-03-14T07:19:19.680112"
    },
    {
      "content": "#### Section 2: Spectroscopic characterization of nanomaterials\nAs we discussed in Chapter 8 on light-matter interactions, the\nconfinement of electrons in a nanomaterial gives rise to properties that\nare related not only to the composition of the particle but to its\nphysical dimensions. Thus, it is possible to detect light that is\nscattered, absorbed and scattered, or absorbed and re-emitted by the\nprocess of fluorescence or phosphorescence. Alternatively, interrogation\nwith a high-energy beam of *something* triggers the ejection of some\nother type of particle or radiation. The key insight in spectroscopy is\nthat the energies of these ejected or scattered waves or particles\ncorrespond in a very specific way to the atoms, molecules, or materials\nunder interrogation.\n\nWhen taking spectra from particles in solution, where solvent and solute\nare totally mixed up, you get a single spectrum containing information\nfrom everything in solution. However, when dealing with solid samples,\nit is possible to obtain spectra from one region of the solid at a time.\nSuch spectra can be used to generate an image by plotting the spatially\nresolved intensity of one or more signals. Such an image can be used on\nits own or overlayed on top of an image using more conventional\ntechniques. This modality gives you information about the composition of\nthe structure and also the location of different atoms or bonding\narrangements between atoms in an image, and hence within an object. For\nexample, granite is an igneous rock composed of many different mineral\ntypes. Putting a sample of granite in an electron microscope equipped\nwith an X-ray detector allows you to distinguish the location of the\nminerals that make it up.\n\n### 14.2.1. Nuclear magnetic resonance, NMR\n\nSubatomic particles like electrons, protons, and neutrons have a\nproperty known as spin. Remember from high school chemistry, you drew\n\"up\" and \"down\" arrows when populating atomic orbitals with pairs of\nelectrons (one up, one down)? That notation was supposed to represent\n**spin**. It is a property that allows twice as many electrons to occupy\nthe same orbital without creating huge repulsive forces by the Pauli\nexclusion principle.[^14.2.1] You may remember that when constructing the\norbital energies like 1$s^2$, 2$s^2$, 2$p^6$, and so on, the electrons\nare paired antiparallel in their respective orbitals or energy levels.\nWhen spins are unpaired, the particle exhibits magnetic activity.\n\nThe concept of spin extends to other subatomic particles as well. For\nexample, when the nucleus of an atom has an odd number of protons and\nneutrons---e.g., $^1$H or $^{13}$C---the nucleus itself can be oriented\nin a magnetic field. In fact, it can be thought of as a little bar\nmagnet with a north and south pole. This magnetically active arrangement\ncan be exploited to learn something about the chemical environment of\nthe atom.\n\nThe technique for molecular structure determination by exploiting this\ninherent magnetism of odd-numbered nuclei is called **nuclear magnetic\nresonance (NMR)**. In NMR, a dilute solution of a molecule of interest\nis placed inside a strong electromagnet cooled by liquid helium. This\nelectromagnet aligns all of the magnetic moments in a single direction.\nOnce aligned, a radio-frequency electromagnetic pulse can be applied.\nSome of this radiation is absorbed by the nuclei, which flips the spin\nfrom one orientation to another. As the magnetic moment goes back into\nalignment with the field, some energy is released in the form of EM\nradiation. This radio-frequency energy is transformed into a spectrum.\nThe spectrum that is produced gives information on the electromagnetic\nenvironment of the magnetically active nuclei. For example, a hydrogen\natom, which has a total spin of one half because it has an odd number of\nnucleons (i.e., a single proton), will resonate at a different frequency\ndepending on its chemical environment. In fact, $^1$HNMR is by far the\nmost useful and popular kind of NMR spectroscopy. For many organic\nmolecules, it is not necessary to use any other spectroscopic technique\nto discern the structure.\n\n$^1H$NMR derives its usefulness from the fact that every hydrogen atom\nhas a different resonant energy depending on the density of electrons\nsurrounding it. Thus, it is usually possible to piece together the\nentire structure based on the precise energy of every hydrogen atom in\nthe molecule. Moreover, the **chemical shift** of the hydrogen atom is\npredictable based on a handful of simple rules. For example, if the\nhydrogen atom is attached to an electronegative element like oxygen, the\nsignal will be *de-shielded* by a predictable amount; if the hydrogen\natom is connected to an electropositive element like silicon, the\nresulting signal is said to be *shielded*, also by a predictable amount.\nShielded and de-shielded atoms nuclei can be easily resolved by NMR\nspectroscopy, with the resolution increasing with the strength of the\nmagnetic field. The strength of the signal (the area under the curve, or\nthe *integral*) also corresponds to how many atoms of a particular type\nare within a molecule.\n\nTo convert from the standard output of NMR software, where the signals\nare given in parts per million (ppm) to frequency of the emitted signal\n(and equivalently, energy), one uses the following formulae, equations\n(14.1) and (14.2)\n\n(Equation 14.1)\n$$\\delta_{\\text{Hz}} = \\delta_{\\text{ppm}} \\times \\text{frequency}_{\\text{MHz}}$$\n\n(Equation 14.2) $$E = h \\times \\nu$$\n\nwhere $\\delta_{\\text{Hz}}$ is the chemical shift in Hz,\n$\\delta_{\\text{ppm}}$ is the chemical shift in ppm,\n$\\text{frequency}_{\\text{MHz}}$ is the operating frequency of the NMR\nspectrometer in MHz, $E$ is energy $h$ is Planck's constant, and $\\nu$\nis frequency in Hz.\n\nThe NMR spectrum can also give information as to the mutual arrangement\nor location of atoms attached to molecules at different points. They do\nthis by *through bond* or *through space* **coupling**. There are many\nexcellent references on the collection and interpretation of NMR spectra\nand we will not go into here. See Figure (14.1) below for a couple of\nexamples of molecules matched to spectra.\n\n(Figure 14.1) \n>>>image(NMR.png.0)\n\n### 14.2.2. Ultraviolet-visible spectroscopy, UV-vis\n\nOne of the most common forms of spectroscopy involves the use of\nultraviolet and visible wavelengths of light to probe electronic\ntransitions in the molecules or particles. Photons in the UV-vis range\ntend to have energies commensurate with the band gaps of molecules,\nparticles, and surfaces. That is, absorption of photons that correspond\nto the promotion of electrons from the valence band to the conduction\nband (when talking about inorganic materials) or from the highest\noccupied molecular orbital (HOMO) to the lowest unoccupied molecular\norbital (LUMO) (when talking about molecules). Given that the energies\nof photons absorbed correspond to the transitions of electrons between\nenergy levels, UV-vis spectroscopy is often called **electronic\nabsorption spectroscopy**. Figure (14.2) shows the key features of a\nUV-vis spectrum.\n\n(Figure 14.2) \n>>>image(UV-vis.png.0)\n\nThe UV-vis spectrum is usually plotted with absorption on the $y$-axis\nas a function of either wavelength (in nm) or energy (in eV). The\nconvention used weirdly depends on who is plotting the data: chemists,\nbiologists, and some engineers tend to plot the absorption as a function\nof wavelength, while physicists and other engineers plot it as a\nfunction of energy. Since wavelength is inversely proportional to\nenergy, the plots appear as mirror images of each other.[^14.2.2] Note that\nwhile the differences between energy levels correspond to discrete\nphoton energies, the absorption spectra nevertheless appear as smoothed\nout curves, rather than lines. The broadening of the spectrum arises\nfirst from the *density of states* below the valence band and above the\nconduction band. Other effects that lead to broadening involve\nperturbations of the energy levels caused by molecular collisions with\neach other and with solvent molecules, formation of energy levels\nspanning multiple molecules from supramolecular organization (e.g.,\ncrystallization), and fluctuations of the energetic levels due to\nelectrostatic (e.g., van der Waals) forces. Despite the broadness of the\nabsorption profile, it is common practice to take the onset of\nabsorption as corresponding to the lowest energy photon absorbable by\nthe system and thus equivalent to the band gap. Usually, one takes the\nslope tangent to the beginning of the curve and extrapolates toward the\n$x$-axis, as shown in Figure (14.2). The $x$-intercept is taken as the\nband gap.\n\nUV-vis spectroscopy can be used to measure effects beyond the bandgaps\nof molecules and semiconductors. For example, the localized surface\nplasmon resonances (LSPRs) of metallic nanoparticles often also lie in\nthe ultraviolet or visible region of the electromagnetic spectrum. When\nplaced in solution, colloidal metallic nanoparticles such as nanowires,\nnanocubes, and nanospheres absorb and scatter wavelengths of light that\ndepend on the shape of the nanoparticle and the atoms(s) of which it is\ncomposed. Recall that anisotropic nanoparticles like wires will have\nmultiple LSPRs, one for each dimension (a spherical or cubic particle\nwould have only a single resonance). The smaller dimensions will\nresonate at higher energies than the larger ones. Thus, in solution,\nwhere the particles are spinning and tumbling around randomly, all of\nthe LSPRs will be visible at once. However, if one deposits such\nstructures on glass or silicon using shearing forces during the\ndeposition, it is possible to get the particles to line up. Such\ndeposited structures will exhibit **birefringence**---in which polarized\nlight will trigger the LSPRs unequally. By using light with different\npolarizations, it is possible to tease out the energies of the LSPRs\nalong the different axes (Figure (14.3)).\n\n(Figure 14.3) \n>>>image(LSPR.png.0)\n\nFinally, we note that such absorption behavior arising from electronic\ntransitions and LSPRs are not strictly limited to the range of photons\nin the UV-vis region. In fact, many kinds of semiconductor nanocrystals\nabsorb in the near-infraried (NIR), and plasmonic nanoparticles with\ndimensions of more than a few hundred nanometers also resonate in this\nrange. Thus, the technique is often referred to as UV-vis-NIR.\n\n### 14.2.3. X-ray photoemission spectroscopy, XPS\n\nWe have seen above how photons can affect transitions of electrons from\none band to another within a solid. However, with high enough incident\nenergies of photons, electrons can be completely ejected from the\nsurface of a material. This phenomenon is called the **photoelectric\neffect** (Figure (14.4) and was the basis of Albert Einstein's sole\nNobel Prize.[^14.2.3] In this theory, the kinetic energy of an electron\nejected from the surface of a solid is given by\n\n(Equation 14.3) $$E = h\\nu - \\phi$$\n\n(Figure 14.4) \n>>>image(photoelectric.png.0)\n\nwhere $E$ is the energy (kinetic energy, because the electron is\nmoving), $h$ and $\\nu$ are Planck's constant and the frequency of the\nincoming photon, and $\\phi$ is the **work function** of the surface. The\nwork function is conceptually similar to the **ionization energy**.\nHowever, the ionization energy refers to the energy required to extract\nthe outermost electron from an atom in the gas phase, whereas the work\nfunction is the energy required to extract an electron from the surface\nof a material made of many atoms. The work function is always less than\nthe ionization energy for individual atoms of the same element. In part,\nthis difference arises because of the strong electrostatic attraction of\nan electron to an ion in the gas phase; in a solid, the positive charge\nleft behind can more or less freely delocalize. Moreover, for an atom in\nthe gas phase, the ionization energy is taken as the energy of an\nelectron in the outermost (highest energy) occupied orbital. In a solid\nmetal, the outermost electrons are involved in strong metallic bonding.\nIn metallic solids, the energy of the outermost electrons is increased\nto a value called the **Fermi level**, which represents the average\nenergy of the conduction electrons. The Fermi level is sometimes called\nthe *electrochemical potential* of the electrons.\n\nWhen a photon of an energy equal to or greater than the Fermi level of\nthe metal surface, an electron is ejected. The finding illustrates one\naspect of the nature of light, namely the relationship between energy\nand intensity. Among other observations, Einstein noted that increasing\nthe brightness or intensity of the light does not increase the energy of\nthe ejected **photoelectrons**, but it does increase their number. This\ninsight into the energies of photoelectrons---namely that they are\nquantized and always have the same energies---is the basis for elemental\nanalysis by a technique called **X-ray photoelectron spectroscopy\n(XPS)**.\n\nIn the traditional conception of measurements of the photoelectric\neffect, the incident beam is in the ultraviolet or visible region of the\nelectromagnetic spectrum. Photons with wavelengths in this range can\nknock loose electrons in the highest energy atomic orbitals, or at the\nFermi level of the metal. However, if a beam made of much higher energy\nphotons is used, such as a beam of X-rays, it is possible to penetrate\nmuch deeper into the atomic structures. In XPS, a high-energy beam of\nphotons (X-rays, $\\lambda$ = 0.834 nm, E = 1486 eV, from an aluminum\nsource) blasts the surface of the sample. The collisions cause many\nelectrons to be ejected. These electrons can originate from any\nelectronic energy level within the atom. Recall from your chemistry\nclass that these energy levels correspond to the levels of 1s, 2s, 3p,\nand so on. The further inside the atom, toward the nucleus, the more\ntightly held the electron, and thus the greater energy needed to eject\nit. However, once the electron is ejected, it arrives at a detector with\n*less* energy than those which were on the outside---i.e., higher\nenergy---of the atom. The reason is that it took a lot of energy to\ndislodge the electron from the inner core, as implied by equation\n(14.3).\n\nGiven that every atom of any element has exactly the same energies for\nelectrons, the energies of the electrons ejected create a spectrum akin\nto a fingerprint. Thus, it is possible to determine the elemental\ncomposition of a material, at least near the surface. (The technique\nworks for the first 10 atomic layers or so.) See Figure (14.5) for an\nillustration of a typical XPS spectrum.\n\n(Figure 14.5) \n>>>image(XPS.png.0)\n\n### 14.2.4. Energy dispersive X-ray spectroscopy\n\nA related technique to XPS is **energy dispersive X-ray spectroscopy\n(EDS)**. The major difference, at least operationally, is that in XPS\nthe incident beam is an X-ray and the emitted beam is made of electrons;\nin EDS, the incident beam is an electron beam whereas the emitted beam\nis X-ray photons. In brief, an energetic beam of electrons strikes the\natoms that make up a material, see Figure (14.5). These energetic\ncollisions knock inner-shell electrons into free space. So far, EDS\nsounds a lot like XPS. However, it is not the ejected electrons are\ndetected, but rather *the photons released when outer-shell electrons\nfill in the holes left by ejected inner-shell electrons*. These photons\nare generally in the X-ray region of the electromagnetic spectrum. As in\nXPS, the spectrum of energies produced creates a pattern unique to each\natom, like a fingerprint.\n\nThe EDS process is generally performed inside of a scanning electron\nmicroscope (SEM, described in detail in the next section). The beam\nscanned across the sample to generate the image also triggers the\nproduction of X-rays. Thus, the SEM equipped with an X-ray detector can\nsimultaneously perform the imaging and the elemental analysis. It is\nthus possible to overlay an elemental map on top of an electron\nmicrograph (image). In this type of composite image, different elements\nare indicated using different colors. Electron microscopy plus EDS\nanalysis is a powerful tool to examine nanomaterials and the nanoscale\nstructures of larger samples.\n\n[^14.2.1]: Which says that particles having all the same properties cannot\n    occupy exactly the same space---they *exclude* each other.\n\n[^14.2.2]: Recall that one can convert between wavelength and energy using\n    the conversion factor of 1240 eV nm. Simply take the quantity you\n    have and divide it into the conversion factor to obtain the other\n    quantity. Thus a photon with an energy of 2 eV has a wavelength of\n    620 nm, and vice versa.\n\n[^14.2.3]: Despite possibly more important---and unquestionably deeper---work\n    in the realm of relativity theory.\n",
      "role": "assistant",
      "timestamp": "2025-03-14T07:20:32.139367"
    },
    {
      "content": "Do you have any questions?",
      "role": "assistant",
      "timestamp": "2025-03-14T07:20:32.291342"
    },
    {
      "content": "14.2.3: is the photoelectron reflected?",
      "role": "user",
      "timestamp": "2025-03-14T07:23:46.346756"
    },
    {
      "content": "The photoelectron is not reflected, but rather ejected from the material. The section explains that when a high-energy photon (like an X-ray) hits the surface, it causes electrons to be completely ejected from the material. These ejected electrons are then detected to create the XPS spectrum. Would you like me to clarify any specific part of this process?",
      "role": "assistant",
      "timestamp": "2025-03-14T07:23:49.316327"
    },
    {
      "content": "#### Section 3: Taking pictures of nanomaterials using the scattering of light and charged particles\nThe goal in characterizing nanomaterials is to prove you have what you\nthink you have. Spectroscopy is great at providing clues as to the\natomic and molecular level details of materials. However, it is not\nalways possible to use spectroscopic techniques to determine the shapes\nand sizes of particles without other information. Moreover, it is\ngenerally impossible to determine the arrangements of particles in a\nsolid structure in either two or three dimensions using spectroscopy\nalone. Imaging techniques, on the other hand, can provide this\ninformation. In general, an image is produced by the observation of\nreflected or transmitted waves. These waves can be in the form of\nphotons, electrons, or even other charged particles. Often, multiple\nimaging modalities are used on the same sample. Images from multiple\ntechniques can also be combined to form a **composite image**.\n\n### 14.3.1. Optical microscopy\n\nPretty much everyone reading this book has used an optical (that is,\nlight) microscope in a high school science class. When I was a kid, I\nwas given a used Tasco microscope with 5x, 10x, 20x, and 50x objectives.\nIt came with a single slide containing dried algae cells. I explored\nevery square micron of that sample. It was like a microscopic universe.\nLater, at a garage sale, I picked up a box of fixed samples in\nmicroscope slides which included several slices of plant and animal\ntissue. I even tried to generate my own samples but didn't have the\nability to make ultrathin sections, so I couldn't get light to pass\nthrough my samples, as my microscope was equipped with illumination from\nthe bottom only.[^14.3.1]\n\nA microscope contains many lenses whose basic function is as a\nmagnifying glass. In short, a lens which is convex on both sides (like\nan almond) bends light rays in such a way as to make the object appear\nlarger when the reflected light enters the eye. A modern optical\nmicroscope contains many such lenses which compounds the magnification\nof each lens, i.e., a **compound microscope**. For example, a 10$\\times$\n**objective** and a 10$\\times$ **eyepiece** yields a total magnification\nof 100$\\times$.\n\nThe total achievable magnification of optical microscopy is about\n1,000$\\times$. The smallest sized object resolvable by an optical\nmicroscope is around 1 $\\mu$m; any smaller and the object just blends in\nwith the background. The reason for the inability to resolve features\nany smaller is because of the **diffraction limit** of light (which\nincidentally also applies to beams of other kinds of photons and\nsubatomic particles). The diffraction limit is a consequence of the\nwave-like nature of light. Just as waves on the surface of a pool\ndiffract or bend around corners, light bends around objects and makes\nthe edges appear blurry. When there is more \"blur\" than \"object,\"\nnothing is seen. While more powerful lenses can be used which boosts the\nnominal level of magnification beyond 1000$\\times$, the microscope will\nstill not be able to resolve smaller features, at least when one is\nusing visible wavelengths of light under **bright field** illumination.\nThe term *bright field* refers to the fact that the objective lens\ncollects all light that is reflected (when illuminated from the top,\nused for opaque specimens), transmitted (when illuminated from the\nbottom, used for transparent specimens, or scattered from the specimen.\nThe intensity of the reflected or transmitted light dominates the\nscattered light.\n\nAs a student working in nanotechnology, however, my favorite mode of\noptical microscopy was not bright field but **dark field** imaging. In\ndark field---which in nanoengineering is generally used to image samples\nimmobilized on an opaque or reflective substrate like silicon---it is\npossible to see, if not resolve, objects that are much smaller than 1\n$\\mu$m. Dark field imaging works by blocking the path of light rays that\nare reflected or transmitted directly from the specimen to the eye. Only\nlight that is scattered with a lateral component is collected and makes\nits way to the objective. Dark field imaging is particularly good at\nvisualizing the edges of objects, as these discontinuities in materials\nlight up like glowing hot filaments (they are not actually glowing or\nhot). Moreover, nanoparticles made of metals actually scatter light at\nthe wavelengths of their localized surface plasmon resonances. Thus, a\ngold nanowire with a 20 nm width appears a different color than a gold\nnanowire with a 30 nm width. Such differences in color can easily be\nresolved by the human eye.[^14.3.2]\n\n#### Fluorescence microscopy\n\nOther modalities of optical microscopy include **fluorescence\nmicroscopy** and various forms of **polarization microscopy** (discussed\nin the next paragraph). Fluorescence microscopy is a ubiquitous tool in\ncell biology. In particular, cells and tissues can be imaged by\nfluorescent stains, proteins (e.g., **green fluorescent protein, GFP**),\nand nanoparticles. Fluorescence microscopy uses a higher energy\nexcitation beam to stimulate fluorescent emission in the fluorescent\nspecies. The reflected light used for excitation, along with the emitted\nfluorescent light, travels through a **band pass filter**, which is\ntuned to block the higher energy used for excitation. Thus, what results\nis an image in which the fluorescent species light up. In biology, this\ntechnique is commonly used to identify cells that carry certain genes,\nsince the gene for the fluorescent protein can be co-located in the\ncell.\n\nAs you might imagine, fluorescence microscopy is highly valuable in\nexperiments involving quantum dots and other fluorescent nanoparticles\nas imaging agents. For example, it can be used to see how quantum dots\nare distributed in cells between organelles. It can also be used to see\nwhat sizes, shapes, and chemical functionalities lead to this\npartitioning. It is thus an immensely important tool in basic research\nin nanomedicine and nanoparticle-based strategies for biomedical\nimaging.\n\n#### Polarization Microscopy\n\nPolarization microscopy is a technique that takes advantage of the\nproperty of **birefringence**, or unequal absorption of a material\nsample with respect to **polarization**. Polarization refers to the\ndirection of oscillation of electromagnetic waves. That is, the\npolarization is with respect to the angle of the amplitude of these\ntransverse waves. Materials develop the property of birefringence when\nthey have structures exhibiting a high degree of **anisotropy**. That\nis, a preferential direction of the components. For example, a box of\nuncooked spaghetti with all the individual noodles aligned parallel to\none another is highly anisotropic. Once the spaghetti is cooked and\nlooks like a jumbled mess in the pot, it is said to be **isotropic**.\nWhen the structures that make up the solid are themselves highly\nanisotropic---meaning that they are longer than they are wide---there is\nthe potential for birefringence.\n\nTwo mechanisms of polarization that have come up so far in this book are\n**wire grid polarization** and **absorptive polarization**. A wire grid\npolarizer is made of an array of thin, parallel wires on a transparent\nsubstrate. These wires have widths of less than 1 $\\mu$m, with a spacing\nof roughly equal width. When unpolarized light is incident upon these\nwires, the electromagnetic waves cause the conduction electrons in the\nmetal to slosh (i.e., oscillate) back and forth. Since the lengths of\nthe wires are, needless to say, longer than the widths, only\npolarizations parallel to the lengths can trigger this sloshing. Light\nof this polarization is thus reflected or scattered, just as the flat\nmetal surface behind the glass plane of a mirror does. Light polarized\nperpendicularly to the parallel wires does not trigger the oscillation\nof the conduction electrons of the wires. The reason is that the\nsubmicron, transverse widths of the metal wires are too short to support\nthese oscillations. Thus, components of light with polarizations\nperpendicular to the wires are transmitted through.[^14.3.3] Figure (14.6)\nshows a schematic diagram of the light that is blocked by and\ntransmitted through a wire grid polarizer.\n\n(Figure 14.6) \n>>>image(polarization.png.0)\n\nAbsorptive polarization is conceptually similar to wire grid\npolarization. The major difference is that where wire grid polarization\nuses metal wires to reflect light, absorptive polarization uses aligned\nmolecules to absorb it. There are many classes of materials that can\nbehave as absorptive polarizers. Polarizers derived from organic media\n(e.g., polymers) are often called **Polaroids** after the company that\ndeveloped them. These organic polarizers are often based on a polymer\nfilm (often polyvinyl alcohol) that is solidified while it is being\nstretched. Thus, the molecules align along the stretched axis. If these\npolymer chains are not inherently absorbing, they can be chemically\noxidized, using, e.g., iodine, to render it so. These Polaroid films are\nubiquitous in liquid crystal displays. (In fact, you are probably\nlooking through at least one Polaroid film if you are reading the\nelectronic version of this book!) Another common application of organic\npolarizers are in polarized sunglasses, which reduce glare originating\nfrom flat reflective surfaces like windshields, road surfaces, and\nwater.[^14.3.4]\n\nAll of the above is to say that if a polarizer is inserted between the\nlight source and the sample, the polarized components of the sample\nappear to \"pop out.\" Thus, it is possible to differentiate domains of\nmaterials which have different atomic or molecular orientations, even\nthough it is not possible to see the atoms or molecules themselves.\nAnother technique, called **cross-polarization**, can be used to\nvisualize structures with radially symmetric orientations, like a\nsnowflake. The \"Maltese cross\" that appears when a cross section of a\npolymer **spherulite** is placed in between two polarizers oriented 90\n$^{\\circ}$ from each other is a result of this effect. Namely, polarized\nlight incident on the sample from the first polarizer is partially\nrotated by the specimen, and then rotated once more by the polarizer\nbetween the specimen and the eyepiece.\n\nWhen I occasionally have visitors to my lab, they may notice my compound\noptical microscope (one of my first purchases as a new professor!).\nThese visitors sometimes express disbelief that information about\nmolecular and nanoscale structure can be derived from plain-vanilla\noptical microscopy! Then I tell them about the features that appear\nunder dark-field and fluorescence microscopy, and what information can\nbe gleaned simply from inserting one or more polarizers into the beam\npath. However, all such information provides indirect evidence of\nstructure; one has to know the theory of light-matter interactions in\norder to divine something about the size, structure, or composition of\nthe specimen. To truly \"visualize\" the sample, beams with wavelengths\nmuch smaller than the wavelength of visible light are needed. To that\nend, we turn to microscopy using beams of electrons.\n\n### 14.3.2. Scanning electron microscopy\n\nThe history of electron microscopy can be traced back to de Broglie, who\npostulated the **wave-particle duality** of matter. This postulate\nsuggests that all matter has a wavelength, which is inversely\nproportional to its mass. It is one of the fundamental postulates of\nquantum mechanics. Specifically, the wavelength of any particle can be\nshown by (14.4) to be\n\n(Equation 14.4) $$\\lambda = \\frac{h}{mv}$$\n\nwhere $m$ is the mass of the particle and $v$ is its velocity. So, for\nparticles that have finite mass, very small wavelengths are possible. If\nthe wavelength of an interrogating beam is brought down to a size\nsmaller than the object being imaged, it is possible to resolve the fine\ndetails of its structure. Thus, most images of viruses, catalysts, and\ntransistors in integrated circuits are obtained not with optical\nmicroscopy but with **scanning electron microscopy (SEM)** (Figure\n(14.7)).\n\n(Figure 14.7) \n>>>image(SEM.png.0)\n\nIn SEM, a beam of electrons is generated by putting several kV of\nelectrical potential across a metal (e.g., tungsten) filament. A current\nflows through the filament, and the heat generated causes some of the\nelectrons to be ejected. Another electrical potential directs the beam\nin the direction of a **stage**, which holds the **specimen**.\nElectromagnets near the electron source (**electron gun**) are used to\nguide and focus the electron beam. The beam is **rastered** or\n**scanned** across the surface of the sample; electrons or X-rays are\nejected from each location. The characteristics of the ejected species\nare mapped in grayscale to the image. Thus, the image of the object is\ncreated pixel by pixel, not all at once as in optical microscopy or, as\nwe shall see, transmission electron microscopy (TEM).\n\nThe beam of electrons scanning across a surface is not necessarily a\ngentle process, as one might read Braille with one's fingertips. Rather,\nit is a harsh interrogation; it has to be in order to eject electrons\nand photons---in whose quantized energies much can be gleaned---from the\nspecimen. Nevertheless, the depth at which interaction occurs is limited\nto a few nanometers for metals (which quickly dissipate charge) and a\nfew tens of nanometers for insulators (which do not). The interactions\nbetween the incident beam and the atoms comprising the specimen cause\nseveral types of particles and electromagnetic radiation to be ejected.\nThese scattered species and their characteristics are detected by a\nnumber of **detectors** in the SEM chamber. Sometimes, information from\nmore than one detector is combined to make a composite image.\n\nArguably, the most useful things ejected by the surface after\ninteraction with the incident electron beam are **secondary electrons**.\nA secondary electron is an electron that arises due to an ionization of\nan atom in the sample. It is kind of like a photoelectron generated in\nXPS, except that the excitation source is an electron beam, rather than\na beam of X-rays. Moreover, multiple secondary electrons can be ejected\nfrom a single incident electron, as the result of an \"avalanche\" of\ncollisions within the sample.\n\nThere are two types of detectors for secondary electrons, which differ\nmainly in their location within the chamber, and the information that\ncan be taken from the images they produce. The first type is the\n**Everhart-Thornley detector**, which is located above the stage and off\nto the side. It is pointed at the specimen at an angle. The second type\nis the **in-lens detector**, which as the name implies is located in the\nsame column of hardware that also produces the electron beam. The\ndetector is annular (like a donut) so that the beam can pass through its\nhole from the tungsten filament on the way to the sample. In general,\nthe in-lens detector is better at resolving fine features of the\nmorphology, while the Everhart-Thornley detector produces a better image\nof the topography. It is not uncommon for the user to toggle back and\nforth between the two detectors and watch the image change in real time.\n\nOther ejected species include **backscattered electrons (BSE)**, which\nare electrons originating from the incident beam, but which have been\nscattered elastically, like billiard balls. These electrons can be\ndetected by tweaking the settings on a typical secondary electron\ndetector, or, more commonly, using a detector that is dedicated to BSE.\nDetectors for BSE provide good contrast for elements with different\natomic numbers (\"$Z$ contrast\"). Backscattered electrons can also lose\nenergy; the difference in energy between the incident and reflected\nelectrons can be used for **electron energy loss spectroscopy (EELS)**.\nAnother species ejected, which we have already discussed in our\ndiscussion of EDS, is X-rays. The techniques of EELS and EDS are often\ntreated as being complementary to each other. EDS excels at elemental\ncomposition and is extremely easy to implement and interpret, while EELS\nis sensitive to the ionization state and bonding environment of the atom\nunder investigation.\n\nA few notes about the practicality and hardware used for SEM. Because of\nthe reactive nature of electron beams and scattered species, SEM must be\ncarried out at low pressure. Additionally, biological samples must be\ndehydrated so that they don't explode when the chamber is pumped down to\nbase pressure. Electrically insulating samples must be coated with metal\nto avoid **charging**---the accumulation of charge in the sample by the\nelectron beam---and eventual degradation of the sample. Coating is\ngenerally performed using a relatively inexpensive benchtop sputter\ndeposition system. The most common coating metals are gold,\ngold/palladium alloy, and platinum. Platinum has the smallest grain size\nand is thus used for the highest-resolution applications, but it is\nexpensive. Variants of SEM which permit the introduction of gas in the\nspecimen chamber to circumvent the need to coat the sample are common.\nConventional SEM instruments can be equipped with a *variable pressure*\nmode, in which a small amount of water is injected into the chamber to\ndissipate charge on the sample. There is also full-on environmental SEM\n(ESEM), in which a sophisticated pumping system is used in conjunction\nwith modified analysis of secondary electrons to examine specimens in\nconditions resembling ambient air.\n\n#### Helium ion microscopy\n\nRemember that the de Broglie wavelength of a beam of particles is\ninversely proportional to its mass. A helium nucleus, He$^{2+}$, has a\nmuch larger mass than an electron, and thus can have a correspondingly\nsmaller wavelength when accelerated toward a specimen. This property is\nthe basis of **helium ion microscopy**, which can be considered a\nvariant of SEM. In this type of imaging, a beam of helium ions is\nrastered over a surface. Collisions of these ions with the sample\nproduce many of the same effects that occur in SEM: generation of\nsecondary electrons, X-rays, and so forth. However, given the smaller\nwavelength of a helium ion as compared to an electron, helium ion\nmicroscopy is capable of significantly greater resolution and depth of\nfocus (i.e., how much of the depth of the sample can be in focus at\nonce).\n\n### 14.3.3. Transmission electron microscopy, TEM\n\nThe other major modality in which beams of electrons are used to obtain\nimages of nanostructured materials is **transmission electron microscopy\n(TEM)**. Like SEM, TEM also uses an electron beam, but it is perhaps\nmore conceptually similar to optical microscopy in cases of the latter\nwhen the beam of light is transmitted through a thin transparent sample.\nIn TEM, a specimen of material is made into a thin sheet with a\nthickness of \\<100 nm. For biological samples, samples are created by\nembedding cells or tissues into a resin (e.g., epoxy), and sectioning\nthis composite structure (the \"block\") with an **ultramicrotome**.[^14.3.5]\nSince TEM works best if there is contrast between light and heavy\nelements, the thin sections are \"stained\" with a reagent containing a\nheavy element, such as osmium. In materials science, ultramicrotomy can\nalso be used, but because brittle samples sometimes crumble during the\nmechanical sectioning process, it is somewhat more common to obtain thin\nsamples using **ion milling** (a relatively inexpensive method for\ngeneral purpose thinning) or **focused ion beam (FIB) milling** (in\nwhich a beam of ions can carve thin slabs of materials in precise\nlocations, but which must be done in a vacuum chamber under simultaneous\nSEM imaging).\n\nOnce obtained, the thin specimens are suspended on a disk containing one\nor more apertures. The disk is commonly made of copper or silicon\nnitride. The apertures form the window through which the specimen is\n\"illuminated\" by the electron beam. The transmitted beam is then\nprojected on a screen that historically was something akin to\nphotographic film but is now an array of semiconductor-based detectors,\nsort of like the detector in a digital camera.\n\nOnce the beam passes through the sample, a wide range of information can\nbe collected. First, the shapes of nanoparticles---including quantum\ndots, nanocrystals, viruses, cellular organelles, and other\nmaterials---can be readily obtained. If the structure is crystalline,\nthe electron beam can generate a diffraction pattern akin to that\nobtained using X-ray diffraction. From this diffraction pattern, the\natomic spacing and crystallographic features of the specimen may be\nmeasured. The TEM instrument may also be outfitted with several of the\nancillary detectors found in SEM. For example, it is possible to obtain\nenergy dispersive X-ray spectra (EDS) from a TEM sample, so that one can\ndetermine the elemental composition of a specimen, not just its physical\ndimensions.\n\nRecent developments in TEM include the increasingly sophisticated\nability to visualize organic molecules, even at the single-molecule\nlevel. Moreover, new types of TEM cells can permit the loading and flow\nof liquid through a thin visualization chamber. These semi-transparent\n\"windows\" allow for the direct observation of molecular dynamics and\nself-assembly processes in real time. The power of liquid-cell TEM is\nthat images and even movies can be obtained in contexts that resemble\nthe \"natural\"---non immobilized---environments for such specimens. The\nconsequences of this type of dynamic imaging are profound. New\napproaches to nanoscale drug delivery can be engineered and investigated\nwithout relying on indirect evidence of the dynamics; the conformation\nof large molecules in solution can be confirmed by direct observation\nfor the first time; and even the course of some types of chemical\nreactions involving nanoscale structures.\n\n### 14.3.4. Dynamic light scattering, DLS\n\nAnother technique deserves mentioning here, though its theoretical\ncomplexity precludes a complete discussion. The sizes of colloidal\nparticles in liquids---including the sizes and dynamics of polymer\nblobs---can be determined using the technique of **dynamic light\nscattering (DLS)**. In brief, DLS operates by shining an incident laser\nbeam through a sample. All parts of the sample undergo elastic\n(Rayleigh) scattering in all directions. The scattered beam gets spread\nover a large area on a screen or detector in the form of dots or\nspeckles. If the laser is pulsed at a fixed interval, the evolution of\nthe **speckle pattern** over time provides information as to the\ndynamics of the molecules in solution. Additionally, the spacing between\nthe speckles is related to the sizes of the nanoparticles in solution.\nFiner-grained analysis can even provide measurements of the\nintramolecular spacing between elements of the same molecule (i.e.,\nbetween monomer residues of the same polymer chain).\n\n[^14.3.1]: Ironically, I would later do my PhD in the use of an\n    **ultramicrotome**---a device which uses a diamond blade like a\n    mechanical deli slicer---to fabricate functional nanostructures as\n    an alternative to photolithography.\n\n[^14.3.2]: \"Eyeball spectrometer.\"\n\n[^14.3.3]: I have to admit that I had this backwards until the day I started\n    writing this section. I always assumed that the perpendicular\n    polarization was blocked, and that the parallel polarization\n    \"slipped through\" the polarizer somehow. I swear I learned this\n    somewhere. At any rate, my intuition turned out to be false!\n\n[^14.3.4]: It turns out that glare is composed in part of light polarized by\n    the process of reflection off of such flat surfaces.\n\n[^14.3.5]: We encountered the ultramicrotome as the basis for the\n    nanofabrication technique known as *nanoskiving* in Chapter 12.\n",
      "role": "assistant",
      "timestamp": "2025-03-14T07:26:00.696788"
    },
    {
      "content": "Do you have any questions?",
      "role": "assistant",
      "timestamp": "2025-03-14T07:26:00.850177"
    },
    {
      "content": "Can you explain each microscopy please",
      "role": "user",
      "timestamp": "2025-03-14T07:26:31.947237"
    },
    {
      "content": "Certainly! The textbook covers several types of microscopy. Which specific ones would you like me to explain? I can briefly summarize optical, electron (SEM and TEM), or other types mentioned. Let me know which you're most interested in, and I'll provide a concise explanation.",
      "role": "assistant",
      "timestamp": "2025-03-14T07:26:34.480417"
    },
    {
      "content": "fluorescence",
      "role": "user",
      "timestamp": "2025-03-14T07:27:01.617865"
    },
    {
      "content": "Sure, let's focus on fluorescence microscopy:\n\nFluorescence microscopy uses:\n1. Higher energy excitation beam \n2. Fluorescent stains, proteins, or nanoparticles\n3. Band pass filter to block excitation light\n4. Allows visualization of specific fluorescent species\n\nIt's especially useful for:\n- Cell biology\n- Tracking quantum dots in cells\n- Studying nanoparticle distribution in biomedical applications\n\nWould you like more details on any specific aspect of fluorescence microscopy?",
      "role": "assistant",
      "timestamp": "2025-03-14T07:27:05.532082"
    },
    {
      "content": "#### Section 4: Scanning probe microscopy, SPM\nOne theme that emerges again and again in the field of characterization\ntechniques of nanoscale materials is that while some objects cannot be\nresolved by \"sight,\" they can be resolved by \"touch.\" The power of\nphysical contact as a means of visualizing nanoscale objects derives\nfrom the intense forces that result from van der Waals interactions, and\neven electrical tunneling currents, when two objects come into close\ncontact. Thus, a pointy object---imagine a needle with nanoscale radius\nof curvature---interacts strongly with features on a surface when it is\nin close proximity. If the forces or electrical currents arising from\nthis interaction are mapped to specific locations as the tip (the\n**probe**) is scanned across the surface, an image can be created.\nBelow, we describe a few different modalities of so-called **scanning\nprobe microscopy**, Figure (14.8), and what information can be gleaned.\n\n(Figure 14.8) \n>>>image(SPM.png.0)\n\n### 14.4.1. Atomic force microscopy, AFM\n\nThe most common form of SPM is called **atomic force microscopy**, which\ngets its name from the fact that the forces are derived ultimately from\nelectrons orbiting the nucleus.[^14.4.1] In AFM, a tip with a radius of\ncurvature of a few nanometers is microfabricated from a silicon wafer\nusing more or less standard photolithographic techniques. The tip is\nmade using an anisotropic etch of the silicon, which naturally makes\npyramidal structures under the right conditions. When you buy AFM tips,\nthey typically come in tens or hundreds made into the silicon wafer from\nwhich they were fabricated. To use one, you have to snap it out of the\nwafer. (The process is kind of like when you buy a plastic model kit,\nand the little plastic pieces have to be detached from a big sheet from\nwhich the individual parts were molded.) Often, the silicon surface is\ntransformed into silicon nitride, which is much harder and more durable\nthan elemental silicon.\n\n#### Contact mode\n\nThe conceptually simplest mode with which one can produce an AFM image\nis in **contact mode**. As the name implies, the AFM tip is\ndragged---again, **scanned** or *rastered*---across the surface. The\ndeflection of the tip is measured by shining a fine laser beam on the\nback side (flat side) of the tip, called the **cantilever**. The laser\nbeam is reflected to a semiconductor photodetector, which registers the\nextent of veritcal deflection of the beam. The deflection at each point\nin the rastered image is converted to a color on a height scale and\nplotted to generate the image. It usually takes a few minutes to\ngenerate a complete image. The major downside of AFM in contact mode is\nthat the tip easily becomes stuck to the surface, especially when thin\nfilms of water are present, which is often the case when collecting\nimages in ambient conditions (which is usually the case in materials\nscience).\n\n#### Tapping mode\n\nThe issue of adhesion to the surface in contact mode is circumvented\nwith the use of **tapping mode**. Here, the tip is oscillated up and\ndown at a known frequency, at a short distance above the surface of the\nspecimen. In the presence of some types of materials or regions of the\nsame material, the tip naturally wants to slow down because of strong\npolarizability and van der Waals forces. A servo mechanism keeps the tip\noscillating at the same rate. The additional energy needed to keep the\ntip moving at this frequency is recorded by the instrument.\nSimultaneously, the height is adjusted automatically using information\nfrom the laser/photodetector system. The addition of the oscillation in\ntapping mode also provides the opportunity to collect information about\nthe energy dissipation during each tapping cycle. This information can\nbe plotted in the form of a **phase-contrast image**, which are often\nthe most visually interesting types of AFM images. In principle, they\nare used to identify regions by different mechanical or electrostatic\nproperties, though such images provide qualitative information only.\nQuantitative measurements are infeasible to extract using this method\n(e.g., extremely localized moduli).\n\n#### Other AFM modes\n\nAs you can imagine, the exceptional resolution of AFM imaging and its\nrelative experimental simplicity (especially compared to SEM and TEM)\nhave led to many variants. In particular, nanoparticles or molecules can\nbe attached to the AFM tip for measurements of chemical interactions\nwith, e.g., proteins or cell surface. The tip can also be conductive for\nmeasurements of highly localized conductivity or---if simultaneously\nilluminated---photovoltage or photocurrent. Another variant, AFM-Raman,\nuses a gold-tipped cantilever to simultaneously obtain topographic\nfeatures along with spatially resolved **tip-enhanced Raman scattering\n(TERS, as in SERS) spectra**. AFM instruments can also be configured for\n**nanoindentation**. That is, systems for measuring the mechanical\nproperties of materials. The AFM tip can be driven into the sample as a\nstatic load or with oscillating forces. These techniques can be used to\nmeasure the hardness, plastic yield, and dynamic mechanical properties.\nMoreover, the exquisite control enabled by piezoelectric devices that\ncontrol the AFM cantilever can be adapted for nanolithography as well.\nFor example, as discussed in Chapter 12, the AFM tip can be \"inked\" by\nmolecules or polymer solutions and dragged like a quill pen across a\nsurface to generate a pattern.\n\n### 14.4.2. Scanning tunneling microscopy, STM\n\nThe final way in which scanning probes can be used to acquire images on\nthe nanoscale is using a technique known as **scanning tunneling\nmicroscopy (STM)**. This technique is perhaps the highest resolution\nimaging tool known to science. It can resolve single atoms or molecules.\nFor example, the hexagonal structure of carbon atoms in carbon nanotubes\nor graphene are readily visible to a skilled operator. To acquire an STM\nimage, one applies a voltage between a sharp tip and a surface. The tip\nis brought into near contact with the surface, and is rastered across\nthe sample. The technique works by measuring **tunneling currents**\nbetween the surface and the tip. Tunneling is a quantum mechanical\nphenomenon in which electrons spontaneously disappear from one surface\nand reappear in an adjacent one. There exists a very high **tunneling\nbarrier** between the surfaces---i.e., vacuum or another insulator---but\nthe electron traverses this gulf anyway. The tunneling current is\nexponentially dependent on distance between the two objects, so a very\nsmall change in separation leads to an even larger change in tunneling\ncurrent. Thus, contrast can be achieved between atoms at the surface of\nan object, even though these differences are only a few tenths of\nangstroms.\n\nLike AFM (dip-pen nanolithography) and SEM (electron-beam lithography),\nSTM can also be used to fabricate structures. The smallest human-made\nsymbols ever created have been done by STM. For example, the famous IBM\nlogo was created by scientists led by Donald Eigler in the 1989 by\nmoving atoms of xenon around on a nickel surface. The image was 5 nm\ntall and 17 nm wide, and comprised 35 xenon atoms. This demonstration\nspurred the imagination of many and suggested it was possible for the\nfirst time to construct molecules one by one, and in arbitrary\narrangements. Indeed several simple molecules have been made, with bonds\ncoming into existence by nudging individual atoms toward each other\nusing the STM tip. However, performing this laborious feat on the scale\nof even a fraction of a mole would probably take an enormously\nimpractical amount of time.[^14.4.2]\n\n[^14.4.1]: Not, as one may believe, from atomic or nuclear power.\n\n[^14.4.2]: I stand ready, however, to eat my words.\n",
      "role": "assistant",
      "timestamp": "2025-03-14T07:30:02.600750"
    },
    {
      "content": "Do you have any questions?",
      "role": "assistant",
      "timestamp": "2025-03-14T07:30:02.755228"
    },
    {
      "content": "14.8  can you explain the figure please like high vacuum",
      "role": "user",
      "timestamp": "2025-03-14T07:30:41.725997"
    },
    {
      "content": "Certainly. Figure 14.8 shows different types of scanning probe microscopy (SPM) techniques. The \"high vacuum\" refers to the environment needed for scanning tunneling microscopy (STM). STM requires a very clean, controlled environment to measure the tiny tunneling currents between the probe tip and the sample surface. Would you like me to explain any other specific parts of the figure?",
      "role": "assistant",
      "timestamp": "2025-03-14T07:30:44.480312"
    },
    {
      "content": "#### Section 5: Diffraction-based characterization methods\nAccording to de Broglie, any traveling object has a wavelength, and\nanything that can be described as a wave can diffract and exhibit\nconstructive and destructive interference. When you shine a single beam\nof light from a point source through two adjacent apertures in a screen\n(as in Young's double slit experiment, Figure (14.9)), the two apertures\nbecome two new point sources. As light waves propagate forward from\nthese two point sources, a pattern of constructive and destructive\ninterference occurs, with the maxima in constructive interference\nrelated to the wavelength $\\lambda$ and the spacing between slits $d$ as\nequation (14.5)\n\n(Equation 14.5) $$d \\sin(\\theta) = m \\lambda$$\n\nwhere $\\theta$ is the angle from the slit to the $m^{th}$ interference\nmaximum that appears on the screen opposite the slits. Multiple \"slits\"\nin 2D and 3D would of course lead to more complex diffraction patterns,\nwhich when analyzed can be used to determine the arrangement of atoms in\nany crystal structure, no matter how complicated.\n\n(Figure 14.9) \n>>>image(youngs double slit.png.0)\n\n### 14.5.1. X-ray crystallography\n\nOf course, if one is trying to reconstruct the repeating structure of\natoms in a crystal lattice, one cannot use light of visible wavelengths,\nas in Young's double-slit experiment. You need higher-energy (shorter\nwavelength) photons, specifically, X-rays. The use of X-rays to\ndetermine crystal structures is called **X-ray crystallography**. While\ndoing this topic justice is well beyond the scope of this short section,\ngiven its importance in chemistry, biology, and materials science, and\nin determining the ultimate arrangement of atoms within nanostructured\nmaterials, we mention some of the key concepts, here.\n\n#### Bragg's law\n\nSimilar to the relationship shown in equation (14.5), the relationship\nbetween the $n^{th}$ peak of constructive interference, the spacing\nbetween adjacent planes of atoms $d$, the angle of the incident X-ray\nbeam $\\theta$, and its wavelength $\\lambda$ can be given by equation\n(14.6)\n\n(Equation 14.6) $$n\\lambda = 2d\\sin\\theta$$\n\nwhere Figure (14.9)b illustrates the relationships between the\nvariables. Bragg's Law implies that an in incident beam of X-rays, upon\nstriking the planes of a crystal at angle $\\theta$, produces\nconstructive interference when the path length is equal to an integer\nmultiple of the wavelength. The pattern of constructive\ninterference---termed **reflections**---is called a diffraction pattern,\nwhich is unique to every structure. Hundreds of thousands of materials,\nincluding organic compounds, minerals, and arbitrarily large biological\nmacromolecules have had their structures determined this way.\n\nTo obtain the structure of a 3D object, the crystal of the sample is\nrotated with respect to the X-ray source. At certain angles, maxima in\nthe intensity of the diffraction peaks appears which satisfy Bragg's\nlaw. If one combines the information from all angles that produce\nmaxima, it is possible to determine the entire crystal structure. Of\ncourse, the process is easier said than done and took many years for\nresearchers to achieve the level of sophistication that exists now.\nNevertheless, much of structure determination is now automated by\nsoftware.\n\n### 14.5.2. Limitations of X-ray diffraction\n\nWhen the authors were students, we were taught that X-ray\ncrystallography was the no-compromise solution to solving the structure\nof a new molecule or form of matter. However, some limitations exist:\n\n1.  The technique only works on crystalline phases of matter, and not\n    those that are amorphous, which do not form diffraction patterns\n\n2.  The structure of interest must be practically obtainable in\n    crystalline form; sometimes, synthetic modifications like the\n    addition of heavy atoms must be carried out in order to form a\n    crystalline solid\n\n3.  The sample must be thin enough for X-rays to be transmitted\n\n4.  For some samples, obtaining X-ray diffraction patterns require\n    either a source of high intensity radiation and a short amount of\n    time, or a lower intensity source and a long time; for some samples,\n    it is impractical to obtain diffractograms on lab-scale equipment\n    with relatively weak X-ray sources and a **synchrotron radiation\n    facility** is required to complete the data collection\n\n5.  X-rays interact primarily with the electron clouds of atoms, and\n    thus, the bigger the atom, the stronger the scattering; however,\n    X-rays have trouble resolving atoms with small atomic numbers, like\n    hydrogen\n\n6.  Finally, the conventional way in which X-ray diffraction patterns\n    are obtained involves the passing of the beam directly through a\n    crystalline sample; materials that form thin films---like\n    essentially all polymer coatings and organic\n    semiconductors---require a modified technique, called\n    **grazing-incidence X-ray diffraction**, discussed below\n\n### 14.5.3. Grazing-incidence X-ray diffraction\n\nPolymeric films and coatings are ubiquitous in a range of applications.\nThese, among countless other examples, include nail polish, optical\ncoatings on eyeglasses, anti-smudge coatings on your smartphone or\ntablet, and organic semiconductor layers in OLED display panels. In\norder to engineer these coatings to maximize some particular\nperformance---e.g., mechanical strength or efficiency of light\nemission---it is necessary to understand how the molecules pack in the\nsolid film. Since molecular (and especially polymeric) structures don't\nalways form nice 3D crystals from which it is straightforward to obtain\nconventional X-ray diffractograms, one must instead obtain them from\nthin films.\n\nTo obtain structural detail from a thin film, one uses **grazing\nincidence X-ray diffraction, (GIXD)**. Just like it sounds, the\ntechnique works by shining the X-ray beam at a glancing angle to the\nfilm. The beam diffracts and reflects onto a detector, similar to the\none used for conventional X-ray crystallography. From the diffraction\npatterns, it is possible to obtain information about the distance\nbetween monomers in the polymer and the distance between the polymer\nchains. For $\\pi$-conjugated materials such as those discussed in\nChapter 7---e.g., semiconducting polymers---the polymer chains in\ncrystalline regions are actually separated from each other along two\ndifferent axes. The first axis is the **$\\pi$-$\\pi$ stacking axis**,\nwhich you can think about as the short distance between dinner plates\nstacked in a single drawer of the dishwasher. The second axis is the\n**lamellar axis**, which is like the edge-on-edge arrangement of dinner\nplates considering the ones on both the top and bottom shelves of the\ndishwasher. Just as in conventional X-ray crystallography, amorphous\nmaterials do not generate distinct reflections. The illustration in\nFigure (14.10) shows an idealized picture of what one might expect to\nsee for a GIXD diffraction pattern for a hypothetical molecule or\ncomposite structure.\n\n(Figure 14.10) \n>>>image(GIXD.png.0)\n\n### 14.5.4. Other particle beams for structure determination: neutrons\nand electrons\n\nAs discussed in Section (14.5), there are a number of cases where X-ray\ncrystallography is not the right tool. For example, for samples with a\nlot of low-$Z$ elements (e.g., hydrogen), **neutron radiation** can be\nused. Since neutrons interact with the nuclei of atoms (instead of the\nelectron clouds) neutron scattering can be used to determine differences\nbetween atomic nuclei, even if they differ by a small number of\nneutrons, as in **isotopes**. The isotopic sensitivity can be used in\nsoft, organic, and biological systems by **isotopic labeling**---e.g.,\nthe replacement of hydrogen ($^1$H) with deuterium ($^2$H, a.k.a.\n$^2$D)---for increased contrast in an aqueous background. Moreover,\nunlike X-rays and high energy beams of electrons, neutrons are\nnon-destructive.\n\nFinally, for very small samples, the beam of electrons used in TEM can\ncreate diffraction patterns that can be used to determine structure. In\nelectron crystallography, the sample must be sufficiently thin and\nrobust so as to transmit the electrons without being degraded in the\nprocess. Moreover, in materials characterization facilities, TEM\ninstruments are extraordinarily expensive and often limited to trained\nusers. A great deal of skill can be required to obtain the sample in a\nform in which it can be imaged, and more skill to interpret the data.\n",
      "role": "assistant",
      "timestamp": "2025-03-14T07:31:02.729128"
    },
    {
      "content": "Do you have any questions?",
      "role": "assistant",
      "timestamp": "2025-03-14T07:31:02.881450"
    },
    {
      "content": "I understand the double slit experiment, but can you explain figure 14.9 part b",
      "role": "user",
      "timestamp": "2025-03-14T07:32:02.068545"
    },
    {
      "content": "Certainly! Figure 14.9b illustrates Bragg's law for X-ray diffraction. It shows how X-rays interact with parallel planes of atoms in a crystal lattice. The key elements are:\n\n1. Incident X-rays\n2. Parallel atomic planes\n3. Reflected X-rays\n4. The angle \u03b8\n5. The interplanar spacing d\n\nThe figure demonstrates how the path difference between X-rays reflected from adjacent planes leads to constructive interference when it equals an integer multiple of the wavelength. Does this help clarify the image? Let me know if you have any specific questions about it.",
      "role": "assistant",
      "timestamp": "2025-03-14T07:32:05.595149"
    },
    {
      "content": "#### Section 6: Outlook\nIn this chapter, we tried to give you a flavor of the ways in which\nnanostructured materials are characterized (see Figure (14.11) for a\nsummary). That is, how we know the elemental composition of a structure,\nits bonding arrangement, and its three-dimensional shape.\nCharacterization tools rely on a number of properties of matter the ways\nin which it responds to beams of incident radiation. Other types of\ncharacterization tools involve physical contact---or very near physical\ncontact---with the surface, as in scanning-probe techniques. Finally, we\nhave seen that many tools for characterization have an analogous tool\nfor fabrication. For example, photolithography uses projection optics\ndeveloped for optical microscopy; electron-beam lithography is basically\na scanning electron microscope; and dip-pen nanolithography is a\nco-opting of the hardware used in atomic force microscopy. These\ncharacterization tools are co-developed with technology: the better we\ncan \"see\" our materials, the more rationality we can impart into their\ndesign.\n\n(Figure 14.11) \n>>>image(spectroscopy comparison.png.0)\n",
      "role": "assistant",
      "timestamp": "2025-03-14T07:33:30.158822"
    },
    {
      "content": "Do you have any questions?",
      "role": "assistant",
      "timestamp": "2025-03-14T07:33:30.311779"
    },
    {
      "content": "Can you mention all the key details please",
      "role": "user",
      "timestamp": "2025-03-14T07:35:25.464852"
    },
    {
      "content": "Certainly. The key details from the text include:\n\n1. Characterization methods for nanostructured materials\n2. Tools that analyze elemental composition, bonding, and 3D shape\n3. Use of incident radiation beams\n4. Scanning-probe techniques for surface analysis\n5. Overlap between characterization and fabrication tools\n6. Examples: photolithography, electron-beam lithography, dip-pen nanolithography\n7. Co-development of tools and technology\n8. Importance of visualization for rational material design\n\nWould you like to explore any of these points further?",
      "role": "assistant",
      "timestamp": "2025-03-14T07:35:29.448100"
    }
  ]
}